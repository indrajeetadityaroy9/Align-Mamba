# @package _global_
# Scaling Experiment: Medium Model (200M params)
# Paper Reference: Figure 3
#
# PRIMARY target model for Align-Mamba.
# 16 encoder + 16 decoder layers, d_model=768

defaults:
  - /experiment/_base
  - override /model: hybrid_medium
  - override /data: iwslt14_de_en
  - override /training: default

experiment:
  name: scaling_medium
  paper_ref: "Figure 3 - 200M"
  description: "Scaling experiment: 200M parameter model (primary)"

project:
  name: align_mamba_icml
  seed: 42

logging:
  wandb:
    enabled: true
    tags: ["scaling", "figure3", "medium", "200M", "primary"]
