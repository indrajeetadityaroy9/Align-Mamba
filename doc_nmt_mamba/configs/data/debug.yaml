# Debug data configuration for dry run
# Use with: python scripts/train.py training=debug model=small data=debug

name: opus_books_debug

# CRITICAL: Use document-level dataset (NOT shuffled sentence-level)
dataset_name: opus_books  # Has document boundaries for proper CAT-N

# Tokenizer settings
tokenizer_type: custom  # Use 32K BPE for proper parameter allocation
tokenizer_path: data/tokenizer/tokenizer.json

# Language settings (mBART format - used only if tokenizer_type=mbart)
src_lang: de_DE
tgt_lang: en_XX

# Sequence lengths - shorter for debugging
max_src_length: 512
max_tgt_length: 512

# CAT-N augmentation
cat_n: 3  # Smaller concatenation for debugging
p_concat: 0.5

# Collation mode - test packed sequences
collator_mode: packed

# Data loading - single process for easier debugging
num_workers: 0
prefetch_factor: null  # Must be null when num_workers=0
